\chapter{THỰC NGHIỆM VÀ ĐÁNH GIÁ KẾT QUẢ}
\label{Chapter4}
\section{Bộ dữ liệu ForenSynths}
Bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA} được sử trong quá trình nghiên cứu và huấn luyện. Các hình ảnh thật chủ yếu được trích từ bộ dữ liệu LSUN~\cite{Yu2015ConstructionOA}, ImageNet~\cite{5206848}, trong khi các hình ảnh giả mạo được tạo ra từ các mô hình GAN~\cite{Goodfellow2014GenerativeAN} khác nhau (ProGAN~\cite{karras2018progressive}, StyleGAN~\cite{karras2019style},  CycleGAN~\cite{zhu2017unpaired}, GauGAN~\cite{park2019SPADE}, Deepfakes~\cite{CaliforniaDeepfakes} và nhiều mô hình khác) chi tiết về bộ dữ liệu được thống kê trong Bảng~\ref{tab:forensynths-dataset}. Đây là bộ dữ liệu được nhiều nghiên cứu sử dụng cho nhiệm vụ phát hiện ảnh tạo sinh.
%
\subsection{Thu thập và xử lý hình ảnh}
\label{ssec:thu_thap_va_xu_ly_hinh_anh}
%
Phương pháp thu thập và xử lý dữ liệu ảnh thật và ảnh tạo sinh được Wang~\cite{Wang2019CNNGeneratedIA} thực hiện với các bước chính như sau:
%
%
\begin{enumerate}
	\item Ảnh giả được tạo ra từ các mô hình sinh ảnh mà không áp dụng xử lý hậu kỳ bổ sung. Nếu bộ ảnh giả đã được phát hành chính thức, ảnh được tải về trực tiếp.
	
	\item Số lượng ảnh thật được chọn bằng với số lượng ảnh giả, lấy từ tập huấn luyện tương ứng của từng loại mô hình.
	
	\item Ảnh thật được tiền xử lý theo quy trình được chỉ định bởi từng mô hình, nhằm làm cho phân phối ảnh thật và giả càng giống nhau càng tốt.
	
	\item Độ phân giải ảnh được chuẩn hóa như sau:
	\begin{itemize}
		\item Đối với các mô hình có đầu ra độ phân giải 256×256 (CycleGAN, StarGAN, ProGAN LSUN, GauGAN COCO, IMLE), kích thước ảnh được giữ nguyên.
		\item Với mô hình tạo ảnh có độ phân giải thấp hơn (DeepFake), ảnh được phóng to bằng nội suy \textcolor{red}{bilinear} sao cho cạnh ngắn bằng 256, giữ nguyên tỉ lệ khung hình.
		\item Với mô hình tạo ảnh có độ phân giải cao hơn (ProGAN, StyleGAN, SAN, SITD), ảnh giữ nguyên độ phân giải gốc.
	\end{itemize}
	
	\item Ảnh được cắt thành các phần 224×224 pixel:
	\begin{itemize}
		\item Cắt ngẫu nhiên trong quá trình huấn luyện.
		\item Cắt phần trung tâm trong quá trình kiểm thử.
	\end{itemize}
	
\end{enumerate}
%
%
%Ngoài bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, quá trình đánh giá mô hình được thực hiện trên các bộ dữ liệu khác nhau, giúp xác định tính khái quát của mô hình sau huấn luyện.

\subsection{Tập huấn luyện: Ảnh giả mạo từ mô hình ProGAN}
\label{ssec:tap_du_lieu_progan}
%
Các hình ảnh sinh bởi mô hình ProGAN~\cite{karras2018progressive} trong bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA} được sử dụng cho quá trình huấn luyện của luận văn. 
%
Cụ thể, tập dữ liệu này bao gồm 20 lớp đối tượng (\textit{airplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, tv-monitor}), trong đó mỗi lớp có 18.000 hình ảnh thật được trích từ bộ dữ liệu LSUN~\cite{Yu2015LSUNCO}, 18.000 hình ảnh tạo sinh bằng mô hình ProGAN~\cite{karras2018progressive}, với vector nhiễu đầu vào \( \mathbf{z} \) được lấy mẫu từ phân phối chuẩn đa chiều \( \mathcal{N}(0, I) \).
%
%

Tuy nhiên, chỉ những hình ảnh thuộc bốn trong hai mươi danh mục đối tượng được lựa chọn để huấn luyện gồm: \textit{car}, \textit{cat}, \textit{chair} và \textit{horse}.
%
Điều này đồng nghĩa với việc tập huấn luyện chính thức có 144.000 hình ảnh, trong đó 72.000 hình ảnh được sinh từ mô hình và 72.000 hình ảnh thật được lấy từ tập huấn luyện của từng phương pháp tương ứng.
%
Việc lựa chọn các lớp này tương tự với các nghiên cứu~\cite{Tan2023RethinkingTU}, \cite{Jeong2022FrePGANRD}, \cite{Jeong2021BiHPFBH}, với mục đích thuận tiện hơn trong việc so sánh kết quả.
%
%
\begin{figure}[ht!]
	\centering
	\includegraphics[width=1.0\linewidth]{Images/dataset_progan_samples.png}
	\begin{minipage}{1.0\linewidth}
		\vspace{5mm}
		\caption{Một vài hình ảnh trong tập dữ liệu huấn luyện (các hình ảnh thật ở hàng trên).}
		\label{fig:dataset_progan_samples}
	\end{minipage}
\end{figure}
%

\input{Tables/table-forensynths-dataset.tex}

\subsection{Tập kiểm định: Ảnh giả mạo từ 8 mô hình GAN khác nhau}
%
\label{ssec:tap_kiem_dinh}
%
Tập dữ liệu kiểm định được xây dựng từ bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, bao gồm hình ảnh được tạo ra bởi tám mô hình sinh ảnh khác nhau: BigGAN~\cite{brock2018large}, CycleGAN~\cite{zhu2017unpaired}, Deepfakes~\cite{CaliforniaDeepfakes}, GauGAN~\cite{park2019SPADE}, ProGAN~\cite{karras2018progressive}, StarGAN~\cite{choi2018stargan}, StyleGAN~\cite{karras2019style} và StyleGAN2\cite{Karras2019AnalyzingAI}.  

Đối với mỗi mô hình, 200 ảnh giả và 200 ảnh thật tương ứng được chọn ngẫu nhiên, đảm bảo sự cân bằng giữa hai lớp. Việc sử dụng đa dạng các mô hình sinh ảnh trong tập kiểm định giúp đánh giá khả năng tổng quát hoá của mô hình phát hiện ảnh giả trên các nguồn dữ liệu chưa từng được huấn luyện trực tiếp.

\subsection{Dữ liệu sử dụng để đánh giá mô hình sau huấn luyện}

%
Tập dữ liệu kiểm tra bao gồm các hình ảnh đã được sử dụng trong nhiều công trình nghiên cứu trước đó. Nhằm đánh giá khả năng khái quát của mô hình phát hiện giả mạo,
%
các hình ảnh thật và hình ảnh giả, được sinh từ những mô hình thuộc họ GAN~\cite{Goodfellow2014GenerativeAN} và Diffusion~\cite{Ho2020DenoisingDP}, tương tự như cách tiếp cận trong nghiên cứu của Tan~\cite{Tan2023RethinkingTU}.
%
%
\begin{itemize}
	%\item \textbf{Hình ảnh từ 8 mô hình GAN thuộc bộ dữ liệu ForenSynths}
	%
	\item \textbf{Hình ảnh từ 9 mô hình GAN thuộc bộ dữ liệu Self-Synthesis}~\cite{Tan2023RethinkingTU}, các hình ảnh giả mạo được thu thập từ 9 mô hình GAN~\cite{Goodfellow2014GenerativeAN} khác nhau, bao gồm:
	%
	AttGAN, BEGAN, CramerGAN, InfoMaxGAN, MMDGAN, RelGAN, S3GAN, SNGAN, STGAN. 
	%
	Tổng cộng gồm 36,000 hình ảnh, số lượng hình ảnh thật và giả mạo trong tập dữ liệu là ngang nhau.
	%
	\item \textbf{Hình ảnh từ 8 mô hình Diffusions~\cite{Ho2020DenoisingDP} trong DIRE}~\cite{Wang2023DIREFD}, tác giả sử dụng 8 mô hình Diffusion~\cite{Ho2020DenoisingDP} khác nhau để sinh hình ảnh, bao gồm:
	%
	ADM~\cite{dhariwal2021diffusion}, DDPM~\cite{ho2020denoising}, IDDPM~\cite{Nichol2021ImprovedDD}, PNDM~\cite{Liu2022PseudoNM}, LDM~\cite{Rombach2021HighResolutionIS}, Stable Diffusion v1~\cite{Rombach2021HighResolutionIS}, Stable Diffusion v2~\cite{Rombach2021HighResolutionIS}, Vqdiffusion~\cite{Gu2021VectorQD}.
	%
	Những mô hình này được huấn luyện trên tập ảnh LSUN-Bedroom~\cite{Yu2015LSUNCO} và ImageNet~\cite{5206848}, hình ảnh thật cũng được trích từ hai tập dữ liệu này. Tổng số lượng hình ảnh là 464,000, trong đó 50\% là hình ảnh thật.
	%
	\item \textbf{Hình ảnh từ 4 mô hình Diffusions trong Ojha}~\cite{Ojha2023TowardsUF}, bao gồm 16,000 hình ảnh, trong đó các hình ảnh thật được trích xuất từ tập dữ liệu LAION~\cite{abs-2111-02114}, các hình ảnh giả được tạo từ 4 mô hình Diffusion~\cite{Ho2020DenoisingDP} bao gồm:
	%
	ADM~\cite{dhariwal2021diffusion}, Glide~\cite{nichol2021glide},  DALL-E-Mini~\cite{Dayma_DALL·E_Mini_2021}, LDM~\cite{Rombach2021HighResolutionIS}.
	%
	Quá trình sinh ảnh sử dụng các câu mô tả hình ảnh thật tương ứng để cung cấp thông tin cho mô hình.
	%\item Tập kiểm tra 4
\end{itemize}

\section{Cài đặt môi trường thực nghiệm}

\subsection{Chuẩn bị dữ liệu}
%
Tập huấn luyện (\texttt{train}): Hình ảnh gồm bốn lớp đối tượng: \textit{car}, \textit{cat}, \textit{chair} và \textit{horse}. Các ảnh giả được tạo ra bằng mô hình sinh ProGAN~\cite{karras2018progressive}, trích xuất từ tập dữ liệu tổng hợp \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}.\\
%
Tập kiểm định (\texttt{validation}):
%
Tập dữ liệu được sử dụng trong quá trình huấn luyện nhằm theo dõi hiệu suất mô hình. Các hình ảnh trong tập này được trích xuất từ tám mô hình GAN khác nhau thuộc bộ dữ liệu tổng hợp \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, bao gồm: ProGAN, StyleGAN, StyleGAN2, StarGAN, CycleGAN, GauGAN, BigGAN và DeepFake.
%
Chi tiết đã đề cập tại \ref{ssec:tap_du_lieu_progan} và \ref{ssec:tap_kiem_dinh}. \\
%
Lý do chọn:
\begin{itemize}
	\item Thuận lợi khi so sánh giữa các phương pháp vì đây là tập huấn luyện được nhiều nghiên cứu sử dụng như: Wang~\cite{Wang2019CNNGeneratedIA}, NPR~\cite{Tan2023RethinkingTU}, LGrad~\cite{Tan2023LearningOG}, Ojha~\cite{Ojha2023TowardsUF}. 
	%
	\item Việc lựa chọn hình ảnh cho tập \textbf{train} chỉ từ một mô hình sinh ảnh duy nhất (ProGAN~\cite{karras2018progressive}) nhằm đánh giá khả năng khái quát và hiệu quả thực sự của phương pháp phát hiện. Cách tiếp cận này phản ánh bối cảnh thực tế, trong đó các mô hình sinh ảnh mới liên tục xuất hiện, trong khi dữ liệu huấn luyện thường đến từ các nguồn cũ và có tốc độ cập nhật chậm hoặc không được cập nhật.
	%
	\item Tập kiểm định được xây dựng từ hình ảnh giả mạo của nhiều mô hình GAN khác nhau, nhằm hỗ trợ việc lựa chọn bộ trọng số có khả năng khái quát tốt nhất trong quá trình huấn luyện. Điều này giúp đảm bảo mô hình được đánh giá trên nhiều kiểu dữ liệu sinh, từ đó tăng độ tin cậy của quá trình chọn lựa mô hình cuối cùng.
	%
\end{itemize}
%
\subsection{Cấu hình phần cứng và cài đặt các tham số} Được thiết lập tương tự như các phương pháp \cite{Wang2019CNNGeneratedIA, Tan2023RethinkingTU,Tan2023LearningOG} để giảm tác động của các yếu tố ngẫu nhiên đến kết quả cuối cùng, làm mất tính khách quan khi so sánh, đánh giá giữa nhiều phương pháp. Giá trị thiết lập các tham số bao gồm:
	\begin{itemize}
		\item Optimizer: Adam
		\item Learning Rate $2 \times 10^{-4}$
		\item Batch Size: 64
		\item Framework: Các thử nghiệm được xây dựng bằng thư viện PyTorch.
		\item Cấu hình máy tính: CPU AMD Ryzen 5 5600X 6-Core, 1 $\times$ GPU NVIDIA RTX A4000, 1 $\times$ 16 GB bộ nhớ RAM.
	\end{itemize}

\subsection{Kết quả huấn luyện}

\comment{Bảng này cần sửa lại, nên để thông tin quá trình train qua các epoch, và model performance, acc, TPR, FPR...}
\input{Tables/table1.tex}

\section{Đánh giá mô hình}
%
Nội dung đánh giá bao gồm hai phần chính: Thứ nhất, so sánh và đánh giá độ chính xác của nghiên cứu so với các phương pháp tiên tiến hiện nay (Bảng~\ref{tab:table2},\ref{tab:table3},\ref{tab:table4}). Thứ hai, phân tích hiệu quả sử dụng tài nguyên tính toán và hiệu năng của một số hướng tiếp cận tiêu biểu (xem Bảng ~\ref{tab:model_performance}).
%
%
%
\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.7\textwidth]{Images/tease.png}
	%    \fbox{\rule{0pt}{3in} \rule{3in}{0pt}} % Khung ảnh trống
	\caption{Tổng quan hiệu năng và độ chính xác của một số hướng tiếp cận, trên tập dữ liệu Ojha~\cite{Ojha2023TowardsUF}.}
	\label{fig:teaser}
\end{figure}
\subsection{So sánh và đánh giá về độ chính xác}
%\comment{Nhớ thêm chú thích thuật ngữ 'State-of-the-Art'}\\
%
Luận văn thực hiện so sánh độ chính xác của phương pháp đề xuất với 10 phương pháp tiên tiến, bao gồm: 
CNNDetection~\cite{Wang2019CNNGeneratedIA}, 
Frank~\cite{Frank2020LeveragingFA}, 
Durall~\cite{Durall2020WatchYU}, 
Patchfor~\cite{Chai2020WhatMF}, 
F3Net~\cite{Qian2020ThinkingIF}, 
SelfBland~\cite{Shiohara2022DetectingDW}, 
GANDetection~\cite{Mandelli2022DetectingGI}, 
LGrad~\cite{Tan2023LearningOG}, 
Ojha~\cite{Ojha2023TowardsUF}, 
NPR~\cite{Tan2023RethinkingTU}. 
Kết quả thí nghiệm trong các Bảng~\ref{tab:table2}, \ref{tab:table3}, và \ref{tab:table4} cho thấy phương pháp đề xuất vượt trội hơn so với các phương pháp hiện có. 

Trên bộ dữ liệu 9-GAN, ADOF đạt độ chính xác cao nhất là 94.2\%, vượt qua Ojha~\cite{Ojha2023TowardsUF} với chỉ 77.6\% \ref{tab:table2}, và NPR~\cite{Tan2023RethinkingTU} đạt 93.2\% (xem Bảng~\ref{tab:table2}).

Độ chính xác đạt 98.3\% trên tập dữ liệu DiffusionForensics~\cite{Wang2023DIREFD}, cao nhất trong 10 phương pháp, trong khi đó NPR~\cite{Tan2023RethinkingTU} giữ vị trí thứ hai với 95.3\% (xem Bảng~\ref{tab:table3}). Kết quả này cao hơn DIRE~\cite{Wang2023DIREFD} với 97.9\% ngay trên bộ dữ liệu của chính họ, mặc dù mô hình đề xuất trong luận văn được huấn luyện trên Forensynths~\cite{Krizhevsky2012ImageNetCW}, trong khi DIRE được huấn luyện trên DiffusionForensics.

Ngoài ra, độ chính xác cũng trội hơn RINE~\cite{koutlis2024leveraging} và Ojha~\cite{Ojha2023TowardsUF}(91.1\%) (xem Bảng~\ref{tab:table4}). Đáng chú ý, cả hai phương pháp này đều sử dụng mô hình CLIP~\cite{abs-2103-00020} có số lượng tham số rất lớn, yêu cầu nhiều tài nguyên tính toán.

\input{Tables/table2.tex}

\input{Tables/table3.tex}

\input{Tables/table4.tex}
\subsection{So sánh và đánh giá về hiệu năng}
%
%
Để so sánh về hiệu năng, luận văn thực hiện đo lường các tiêu chí về độ phức tạp của mô hình cũng như số lượng phép toán cần thiết cho mỗi dự đoán (chi tiết xem Bảng~\ref{tab:model_performance}). Tất cả được thực hiện trên máy tính có CPU AMD Ryzen 5 5600X 6-Core, GPU NVIDIA RTX A4000, 16 GB bộ nhớ RAM. Hình ảnh đầu vào có kích thước $256 \times 256 \times 3$. Các tiêu chí đánh giá bao gồm:
%
\begin{figure}[ht!]
	\includegraphics[width=\textwidth]{Images/figure_pine_line_1.png}
	\caption{Quy trình cơ bản của các phương pháp phát hiện ảnh tạo sinh bằng mạng học sâu}	
	\label{figure_pine_line_1}
\end{figure}
%
%
\begin{itemize}
	\item \textbf{Number of Parameters:} Số lượng tham số của mô hình, thể hiện độ phức tạp trong kiến trúc.
	\item \textbf{Input Processing Time:} Đo lường thời gian cần thiết để xử lý hình ảnh trước khi đưa vào mô hình dự đoán, các bước xử lý này thay đổi theo hướng tiếp cận cụ thể (xem Hình.~\ref{figure_pine_line_1}).
	\item \textbf{Inference Time:} Thời gian cần sử dụng cho một dự đoán.
	\item \textbf{FLOPs:} Số lượng phép tính dấu chấm động trong 1 giây, luận văn sử dụng thư viện \texttt{fvcore} để ước tính khối lượng tính toán mà mỗi mô hình cần thực hiện cho một dự đoán.
\end{itemize}
%
%
\input{Tables/table7.tex}




