\chapter{THỰC NGHIỆM VÀ ĐÁNH GIÁ KẾT QUẢ}
\label{Chapter4}
\section{Bộ dữ liệu ForenSynths}
Bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA} được sử trong quá trình nghiên cứu và huấn luyện. Các hình ảnh thật chủ yếu được trích từ bộ dữ liệu LSUN~\cite{Yu2015ConstructionOA}, ImageNet~\cite{5206848}, trong khi các hình ảnh giả mạo được tạo ra từ các mô hình GAN~\cite{Goodfellow2014GenerativeAN} khác nhau (ProGAN~\cite{karras2018progressive}, StyleGAN~\cite{karras2019style},  CycleGAN~\cite{zhu2017unpaired}, GauGAN~\cite{park2019SPADE}, Deepfakes~\cite{CaliforniaDeepfakes} và nhiều mô hình khác) chi tiết về bộ dữ liệu được thống kê trong Bảng~\ref{tab:forensynths-dataset}. Đây là bộ dữ liệu được nhiều nghiên cứu sử dụng cho nhiệm vụ phát hiện ảnh tạo sinh.
%
\subsection{Thu thập và xử lý hình ảnh}
\label{ssec:thu_thap_va_xu_ly_hinh_anh}
%
Phương pháp thu thập và xử lý dữ liệu ảnh thật và ảnh tạo sinh được Wang~\cite{Wang2019CNNGeneratedIA} thực hiện với các bước chính như sau:
%
%
\begin{enumerate}
	\item Ảnh giả được tạo ra từ các mô hình sinh ảnh mà không áp dụng xử lý hậu kỳ bổ sung. Nếu bộ ảnh giả đã được phát hành chính thức, ảnh được tải về trực tiếp.
	
	\item Số lượng ảnh thật được chọn bằng với số lượng ảnh giả, lấy từ tập huấn luyện tương ứng của từng loại mô hình.
	
	\item Ảnh thật được tiền xử lý theo quy trình được chỉ định bởi từng mô hình, nhằm làm cho phân phối ảnh thật và giả càng giống nhau càng tốt.
	
	\item Độ phân giải ảnh được chuẩn hóa như sau:
	\begin{itemize}
		\item Đối với các mô hình có đầu ra độ phân giải 256×256 (CycleGAN, StarGAN, ProGAN LSUN, GauGAN COCO, IMLE), kích thước ảnh được giữ nguyên.
		\item Với mô hình tạo ảnh có độ phân giải thấp hơn (DeepFake), ảnh được phóng to bằng phép \gls{bilinear} sao cho cạnh ngắn bằng 256, giữ nguyên tỉ lệ khung hình.
		\item Với mô hình tạo ảnh có độ phân giải cao hơn (ProGAN, StyleGAN, SAN, SITD), ảnh giữ nguyên độ phân giải gốc.
	\end{itemize}
	
	\item Ảnh được cắt thành các phần $224 \times 224$ pixel:
	\begin{itemize}
		\item Cắt ngẫu nhiên trong quá trình huấn luyện.
		\item Cắt phần trung tâm trong quá trình kiểm thử.
	\end{itemize}
	
\end{enumerate}
%
%
%Ngoài bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, quá trình đánh giá mô hình được thực hiện trên các bộ dữ liệu khác nhau, giúp xác định tính khái quát của mô hình sau huấn luyện.

\subsection{Tập \gls{train}: Ảnh giả mạo từ mô hình ProGAN}
\label{ssec:tap_du_lieu_progan}
%
Các hình ảnh sinh bởi mô hình ProGAN~\cite{karras2018progressive} trong bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA} được sử dụng cho quá trình huấn luyện của luận văn. 
%
Cụ thể, tập dữ liệu này bao gồm 20 lớp đối tượng (\textit{airplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, tv-monitor}), trong đó mỗi lớp có 18.000 hình ảnh thật được trích từ bộ dữ liệu LSUN~\cite{Yu2015LSUNCO}, 18.000 hình ảnh tạo sinh bằng mô hình ProGAN~\cite{karras2018progressive}, với vector nhiễu đầu vào \( \mathbf{z} \) được lấy mẫu từ phân phối chuẩn đa chiều \( \mathcal{N}(0, I) \).
%
%

Tuy nhiên, chỉ những hình ảnh thuộc bốn trong hai mươi danh mục đối tượng được lựa chọn để huấn luyện gồm: \textit{car}, \textit{cat}, \textit{chair} và \textit{horse}.
%
Điều này đồng nghĩa với việc tập huấn luyện chính thức có 144.000 hình ảnh, trong đó 72.000 hình ảnh được sinh từ mô hình và 72.000 hình ảnh thật được lấy từ tập huấn luyện của từng phương pháp tương ứng.
%
Việc lựa chọn các lớp này tương tự với các nghiên cứu~\cite{Tan2023RethinkingTU}, \cite{Jeong2022FrePGANRD}, \cite{Jeong2021BiHPFBH}, với mục đích thuận tiện hơn trong việc so sánh kết quả.
%
%
\begin{figure}[ht!]
	\centering
	\includegraphics[width=1.0\linewidth]{Images/dataset_progan_samples.png}
	\begin{minipage}{1.0\linewidth}
		\vspace{5mm}
		\caption{Một vài hình ảnh trong tập dữ liệu huấn luyện (các hình ảnh thật ở hàng trên).}
		\label{fig:dataset_progan_samples}
	\end{minipage}
\end{figure}
%
\subsection{Tập \gls{validation}:  Ảnh giả mạo từ mô hình ProGAN}
Tương tự như tập \gls{train}, các hình ảnh trong tập \gls{validation} thuộc bốn trong hai mươi danh mục đối tượng gồm: \textit{car}, \textit{cat}, \textit{chair} và \textit{horse}.
%
\input{Tables/table-forensynths-dataset.tex}

\subsection{Tập \gls{test}: Ảnh giả mạo từ 8 mô hình GAN khác nhau}
%
\label{ssec:tap_kiem_dinh}
%
Tập dữ liệu kiểm định được xây dựng từ bộ dữ liệu \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, bao gồm hình ảnh được tạo ra bởi tám mô hình sinh ảnh khác nhau: BigGAN~\cite{brock2018large}, CycleGAN~\cite{zhu2017unpaired}, Deepfakes~\cite{CaliforniaDeepfakes}, GauGAN~\cite{park2019SPADE}, ProGAN~\cite{karras2018progressive}, StarGAN~\cite{choi2018stargan}, StyleGAN~\cite{karras2019style} và StyleGAN2\cite{Karras2019AnalyzingAI}.  

Đối với mỗi mô hình, 200 ảnh giả và 200 ảnh thật tương ứng được chọn ngẫu nhiên, đảm bảo sự cân bằng giữa hai lớp. Việc sử dụng đa dạng các mô hình sinh ảnh trong tập kiểm định giúp đánh giá khả năng tổng quát hoá của mô hình phát hiện ảnh giả trên các nguồn dữ liệu chưa từng được huấn luyện trực tiếp.

\subsection{Dữ liệu sử dụng để đánh giá mô hình sau huấn luyện}

%
Tập dữ liệu kiểm tra bao gồm các hình ảnh đã được sử dụng trong nhiều công trình nghiên cứu trước đó. Nhằm đánh giá khả năng khái quát của mô hình phát hiện giả mạo,
%
các hình ảnh thật và hình ảnh giả, được sinh từ những mô hình thuộc họ GAN~\cite{Goodfellow2014GenerativeAN} và Diffusion~\cite{Ho2020DenoisingDP}, tương tự như cách tiếp cận trong nghiên cứu của Tan~\cite{Tan2023RethinkingTU}.
%
%
\begin{itemize}
	%\item \textbf{Hình ảnh từ 8 mô hình GAN thuộc bộ dữ liệu ForenSynths}
	%
	\item \textbf{Hình ảnh từ 9 mô hình GAN thuộc bộ dữ liệu Self-Synthesis}~\cite{Tan2023RethinkingTU}, các hình ảnh giả mạo được thu thập từ 9 mô hình GAN~\cite{Goodfellow2014GenerativeAN} khác nhau, bao gồm:
	%
	AttGAN, BEGAN, CramerGAN, InfoMaxGAN, MMDGAN, RelGAN, S3GAN, SNGAN, STGAN. 
	%
	Tổng cộng gồm 36,000 hình ảnh, số lượng hình ảnh thật và giả mạo trong tập dữ liệu là ngang nhau.
	%
	\item \textbf{Hình ảnh từ 8 mô hình Diffusions~\cite{Ho2020DenoisingDP} trong DIRE}~\cite{Wang2023DIREFD}, tác giả sử dụng 8 mô hình Diffusion~\cite{Ho2020DenoisingDP} khác nhau để sinh hình ảnh, bao gồm:
	%
	ADM~\cite{dhariwal2021diffusion}, DDPM~\cite{ho2020denoising}, IDDPM~\cite{Nichol2021ImprovedDD}, PNDM~\cite{Liu2022PseudoNM}, LDM~\cite{Rombach2021HighResolutionIS}, Stable Diffusion v1~\cite{Rombach2021HighResolutionIS}, Stable Diffusion v2~\cite{Rombach2021HighResolutionIS}, Vqdiffusion~\cite{Gu2021VectorQD}.
	%
	Những mô hình này được huấn luyện trên tập ảnh LSUN-Bedroom~\cite{Yu2015LSUNCO} và ImageNet~\cite{5206848}, hình ảnh thật cũng được trích từ hai tập dữ liệu này. Tổng số lượng hình ảnh là 464,000, trong đó 50\% là hình ảnh thật.
	%
	\item \textbf{Hình ảnh từ 4 mô hình Diffusions trong Ojha}~\cite{Ojha2023TowardsUF}, bao gồm 16,000 hình ảnh, trong đó các hình ảnh thật được trích xuất từ tập dữ liệu LAION~\cite{abs-2111-02114}, các hình ảnh giả được tạo từ 4 mô hình Diffusion~\cite{Ho2020DenoisingDP} bao gồm:
	%
	ADM~\cite{dhariwal2021diffusion}, Glide~\cite{nichol2021glide},  DALL-E-Mini~\cite{Dayma_DALL·E_Mini_2021}, LDM~\cite{Rombach2021HighResolutionIS}.
	%
	Quá trình sinh ảnh sử dụng các câu mô tả hình ảnh thật tương ứng để cung cấp thông tin cho mô hình.
	%\item Tập kiểm tra 4
\end{itemize}

\section{Cài đặt môi trường thực nghiệm}

\subsection{Chuẩn bị dữ liệu}
%
Tập \gls{train}: Hình ảnh gồm bốn lớp đối tượng: \textit{car}, \textit{cat}, \textit{chair} và \textit{horse}. Các ảnh giả được tạo ra bằng mô hình sinh ProGAN~\cite{karras2018progressive}, trích xuất từ tập dữ liệu tổng hợp \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}.
%
%Tập \gls{validation}:
%%
%Tập dữ liệu được sử dụng trong quá trình huấn luyện nhằm theo dõi hiệu suất mô hình. Các hình ảnh trong tập này được trích xuất từ tám mô hình GAN khác nhau thuộc bộ dữ liệu tổng hợp \textbf{ForenSynths}~\cite{Wang2019CNNGeneratedIA}, bao gồm: ProGAN, StyleGAN, StyleGAN2, StarGAN, CycleGAN, GauGAN, BigGAN và DeepFake. Việc sử dụng tập kiểm định có phân phối khác so với tập huấn luyện cho phép đánh giá khả năng tổng quát hóa của mô hình đối với các loại ảnh giả ngoài phân phối huấn luyện (out-of-distribution validation).
%%
%%
%Chi tiết tập dữ liệu được trình bày tại \ref{ssec:tap_du_lieu_progan} và \ref{ssec:tap_kiem_dinh}. \\
%%
%Lý do chọn tập dữ liệu:
%\begin{itemize}
%	\item Thuận lợi khi so sánh giữa các phương pháp vì đây là tập huấn luyện được nhiều nghiên cứu sử dụng như: Wang~\cite{Wang2019CNNGeneratedIA}, NPR~\cite{Tan2023RethinkingTU}, LGrad~\cite{Tan2023LearningOG}, Ojha~\cite{Ojha2023TowardsUF}. 
%	%
%	\item Việc lựa chọn hình ảnh cho tập \gls{train} chỉ từ một mô hình sinh ảnh duy nhất (ProGAN~\cite{karras2018progressive}) nhằm đánh giá khả năng khái quát và hiệu quả thực sự của phương pháp phát hiện. Cách tiếp cận này phản ánh bối cảnh thực tế, trong đó các mô hình sinh ảnh mới liên tục xuất hiện, trong khi dữ liệu huấn luyện thường đến từ các nguồn cũ và có tốc độ cập nhật chậm hoặc không được cập nhật.
%	%
%	\item Tập kiểm định được xây dựng từ hình ảnh giả mạo của nhiều mô hình GAN khác nhau, nhằm hỗ trợ việc lựa chọn bộ trọng số có khả năng khái quát tốt nhất trong quá trình huấn luyện. Điều này giúp đảm bảo mô hình được đánh giá trên nhiều kiểu dữ liệu sinh, từ đó tăng độ tin cậy của quá trình chọn lựa mô hình cuối cùng.
%	%
%\end{itemize}
%

Tập \gls{validation}:
%
Tập dữ liệu được sử dụng trong quá trình huấn luyện nhằm theo dõi hiệu suất mô hình. Các hình ảnh trong tập này được trích xuất từ mô hình Progan
%
Chi tiết tập dữ liệu được trình bày tại \ref{ssec:tap_du_lieu_progan}\\
%
Lý do chọn tập dữ liệu:
\begin{itemize}
	\item Thuận lợi khi so sánh giữa các phương pháp vì đây là tập huấn luyện được nhiều nghiên cứu sử dụng như: Wang~\cite{Wang2019CNNGeneratedIA}, NPR~\cite{Tan2023RethinkingTU}, LGrad~\cite{Tan2023LearningOG}, Ojha~\cite{Ojha2023TowardsUF}. 
	%
	\item Việc lựa chọn hình ảnh cho tập \gls{train} chỉ từ một mô hình sinh ảnh duy nhất (ProGAN~\cite{karras2018progressive}) nhằm đánh giá khả năng khái quát và hiệu quả thực sự của phương pháp phát hiện. Cách tiếp cận này phản ánh bối cảnh thực tế, trong đó các mô hình sinh ảnh mới liên tục xuất hiện, trong khi dữ liệu huấn luyện thường đến từ các nguồn cũ và có tốc độ cập nhật chậm hoặc không được cập nhật.
	%
%	\item Tập kiểm định được xây dựng từ hình ảnh giả mạo của nhiều mô hình GAN khác nhau, nhằm hỗ trợ việc lựa chọn bộ trọng số có khả năng khái quát tốt nhất trong quá trình huấn luyện. Điều này giúp đảm bảo mô hình được đánh giá trên nhiều kiểu dữ liệu sinh, từ đó tăng độ tin cậy của quá trình chọn lựa mô hình cuối cùng.
	%
\end{itemize}


\subsection{Cấu hình phần cứng và cài đặt các tham số} Được thiết lập tương tự như các phương pháp \cite{Wang2019CNNGeneratedIA, Tan2023RethinkingTU,Tan2023LearningOG} để giảm tác động của các yếu tố ngẫu nhiên đến kết quả cuối cùng, làm mất tính khách quan khi so sánh, đánh giá giữa nhiều phương pháp. Giá trị thiết lập các tham số bao gồm:
	\begin{itemize}
		\item \Gls{optimizer}: \Gls{adam}
		\item \Gls{learningrate}: $2 \times 10^{-4}$
		\item \Gls{batchsize}: 64
		\item Framework: Các thử nghiệm được xây dựng bằng thư viện \Gls{pytorch}.
		\item Cấu hình máy tính: CPU AMD Ryzen 5 5600X 6-Core, 1 $\times$ GPU NVIDIA RTX A4000, 1 $\times$ 16 GB bộ nhớ RAM.
	\end{itemize}

\subsection{Kết quả huấn luyện}

Mô hình ngừng cải thiện trên tập kiểm tra sau 9 \gls{epoch}, cho thấy quá trình huấn luyện đã đạt đến ngưỡng hội tụ. Do đó, mô hình tại \gls{epoch} thứ 9 được chọn làm mô hình cuối cùng để đánh giá hiệu năng.

\input{Tables/table1.tex}

\section{Đánh giá mô hình}
%
Nội dung đánh giá bao gồm hai phần chính: Thứ nhất, so sánh và đánh giá độ chính xác của nghiên cứu so với các phương pháp tiên tiến hiện nay (Bảng~\ref{tab:table2},\ref{tab:table3},\ref{tab:table4}). Thứ hai, phân tích hiệu quả sử dụng tài nguyên tính toán và hiệu năng của một số hướng tiếp cận tiêu biểu (xem Bảng ~\ref{tab:model_performance}).
%
%
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{Images/tease.png}
	%    \fbox{\rule{0pt}{3in} \rule{3in}{0pt}} % Khung ảnh trống
	\caption{Tổng quan hiệu năng và độ chính xác của một số hướng tiếp cận, trên tập dữ liệu Ojha~\cite{Ojha2023TowardsUF}.}
	\label{fig:teaser}
\end{figure}
\subsection{So sánh, đánh giá khả năng phát hiện ảnh tạo sinh từ các phương pháp sinh ảnh khác nhau}
%\comment{Nhớ thêm chú thích thuật ngữ 'State-of-the-Art'}\\
%
Kết quả đánh giá trong mục này là một phần nội dung chính trong bài báo~\cite{adof} đã được công bố tại hội nghị quốc tế SOICT 2024.

%
Luận văn thực hiện so sánh độ chính xác của phương pháp đề xuất với 10 phương pháp tiên tiến trên nhiều tập dữ liệu có phân phối khác so với tập dữ liệu huấn luyện, bao gồm: 
CNNDetection~\cite{Wang2019CNNGeneratedIA}, 
Frank~\cite{Frank2020LeveragingFA}, 
Durall~\cite{Durall2020WatchYU}, 
Patchfor~\cite{Chai2020WhatMF}, 
F3Net~\cite{Qian2020ThinkingIF}, 
SelfBland~\cite{Shiohara2022DetectingDW}, 
GANDetection~\cite{Mandelli2022DetectingGI}, 
LGrad~\cite{Tan2023LearningOG}, 
Ojha~\cite{Ojha2023TowardsUF}, 
NPR~\cite{Tan2023RethinkingTU}. 
Kết quả thí nghiệm trong các Bảng~\ref{tab:table2}, \ref{tab:table3}, và \ref{tab:table4} cho thấy phương pháp đề xuất vượt trội hơn so với các phương pháp hiện có. 

Trên bộ dữ liệu 9-GAN, ADOF đạt độ chính xác cao nhất là 94.2\%, vượt qua Ojha~\cite{Ojha2023TowardsUF} với chỉ 77.6\% \ref{tab:table2}, và NPR~\cite{Tan2023RethinkingTU} đạt 93.2\% (xem Bảng~\ref{tab:table2}).

Độ chính xác đạt 98.3\% trên tập dữ liệu DiffusionForensics~\cite{Wang2023DIREFD}, cao nhất trong 10 phương pháp, trong khi đó NPR~\cite{Tan2023RethinkingTU} giữ vị trí thứ hai với 95.3\% (xem Bảng~\ref{tab:table3}). Kết quả này cao hơn DIRE~\cite{Wang2023DIREFD} với 97.9\% ngay trên bộ dữ liệu của chính họ, mặc dù mô hình đề xuất trong luận văn được huấn luyện trên Forensynths~\cite{Krizhevsky2012ImageNetCW}, trong khi DIRE được huấn luyện trên DiffusionForensics.

Ngoài ra, độ chính xác cũng trội hơn RINE~\cite{koutlis2024leveraging} và Ojha~\cite{Ojha2023TowardsUF}(91.1\%) (xem Bảng~\ref{tab:table4}). Đáng chú ý, cả hai phương pháp này đều sử dụng mô hình CLIP~\cite{abs-2103-00020} có số lượng tham số rất lớn, yêu cầu nhiều tài nguyên tính toán.

\input{Tables/table2.tex}

\input{Tables/table3.tex}

\input{Tables/table4.tex}
\subsection{So sánh và đánh giá về hiệu năng}
%
%
Để so sánh về hiệu năng, luận văn thực hiện đo lường các tiêu chí về độ phức tạp của mô hình cũng như số lượng phép toán cần thiết cho mỗi dự đoán (chi tiết xem Bảng~\ref{tab:model_performance}). Tất cả được thực hiện trên máy tính có CPU AMD Ryzen 5 5600X 6-Core, GPU NVIDIA RTX A4000, 16 GB bộ nhớ RAM. Hình ảnh đầu vào có kích thước $256 \times 256 \times 3$. Các tiêu chí đánh giá bao gồm:
%
\begin{figure}[ht!]
	\includegraphics[width=\textwidth]{Images/figure_pine_line_1.png}
	\caption{Quy trình cơ bản của các phương pháp phát hiện ảnh tạo sinh bằng mạng học sâu}	
	\label{figure_pine_line_1}
\end{figure}
%
%
\begin{itemize}
	\item \textbf{Number of Parameters:} Số lượng tham số của mô hình, thể hiện độ phức tạp trong kiến trúc.
	\item \textbf{Input Processing Time:} Đo lường thời gian cần thiết để xử lý hình ảnh trước khi đưa vào mô hình dự đoán, các bước xử lý này thay đổi theo hướng tiếp cận cụ thể (xem Hình.~\ref{figure_pine_line_1}).
	\item \textbf{Inference Time:} Thời gian cần sử dụng cho một dự đoán.
	\item \textbf{FLOPs:} Số lượng phép tính dấu chấm động trong 1 giây, luận văn sử dụng thư viện \texttt{fvcore} để ước tính khối lượng tính toán mà mỗi mô hình cần thực hiện cho một dự đoán.
\end{itemize}
%
%
\input{Tables/table7.tex}

%Total number of parameters: 456,771 of Student model
%Total number of parameters: 1.4e^6 of Teacher model

\section{Kết quả tối giản mô hình \glsentrytext{student} bằng phương pháp \glsentrytext{fbkd}}
%
Trong phần này, chúng tôi trình bày kết quả thực nghiệm của mô hình \gls{student} được xây dựng bằng cách rút gọn kiến trúc từ mô hình \gls{teacher} thông qua phương pháp \gls{fbkd}. Mô hình \gls{teacher} chính là kiến trúc đã được sử dụng và đánh giá trong công trình công bố tại hội nghị SOICT 2024~\cite{adof}. Mục tiêu của quá trình rút gọn là giảm thiểu độ phức tạp tính toán và kích thước mô hình, từ đó nâng cao khả năng triển khai trên các thiết bị có tài nguyên hạn chế, mà vẫn duy trì hiệu suất nhận diện ở mức chấp nhận được. Chi tiết về kiến trúc và quy trình huấn luyện đã được trình bày tại Mục~\ref{ss:toi_gian_mo_hinh}.

Mô hình Student đạt tổng số tham số khoảng \textbf{456,771}, chỉ bằng khoảng \textbf{1/3} so với \textbf{1.44 triệu} tham số của mô hình Teacher. Điều này cho thấy tiềm năng đáng kể của phương pháp \gls{fbkd} trong việc tối ưu hóa mô hình mà không đánh đổi quá nhiều về mặt hiệu suất.
%
\begin{table}[h!]
	\centering
	\caption{So sánh mô hình \Gls{teacher} và \Gls{student} trên ba tập dữ liệu.}
	\label{tab:teacher_student_comparison}
	\begin{adjustbox}{max width=\textwidth}
		\setlength{\tabcolsep}{12pt} % Tăng khoảng cách giữa các cột
		\renewcommand{\arraystretch}{1.2} % Tăng độ cao dòng
		\begin{tabular}{l c c}
			\toprule
			\textbf{Bộ dữ liệu} &
			\textbf{Mô hình Student (acc/ap)} &
			\textbf{Mô hình Teacher (acc/ap)} \\
			\midrule
			GANGen-Detection      & 94.5 / 98.0        & 94.2 / 98.2 \\
			DiffusionForensics    & {98.1 / 99.8} & 98.3 / 99.8 \\
			UniversalFakeDetect   & {93.4 / 98.0}  & 94.9 / 98.2 \\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
\end{table}
%
Mặc dù số lượng tham số giảm mạnh, mô hình \Gls{student} vẫn đạt được hiệu suất đáng kể trên cả ba tập dữ liệu. Các kết quả trong Bảng~\ref{tab:teacher_student_comparison} được ghi nhận sau khi huấn luyện mô hình \Gls{student} trong \textbf{8 epoch}, sử dụng dữ liệu và chiến lược huấn luyện tương tự như mô hình \Gls{teacher}.
%
%\noindent
Mô hình \Gls{student} đã duy trì được độ chính xác cao, đồng thời giảm đáng kể độ phức tạp, phù hợp với mục tiêu triển khai trên các thiết bị hạn chế tài nguyên.





