\label{glossary}

%backbone
\newglossaryentry{backbone}{
	name={backbone},
	description={Hay còn gọi \textit{mạng xương sống} trong tiếng Việt, là phần cơ bản của mô hình chịu trách nhiệm trích xuất các đặc trưng từ dữ liệu đầu vào. Các cấu trúc phổ biến thường sử dụng làm \textit{backbone} trong các nhiệm vụ liên quan đến hình ảnh gồm ResNet, VGG, và EfficientNet},
	short={backbone},
}
%
%up-sampling 
\newglossaryentry{up-sampling}{
	name={up-sampling},
	description={Toán tử \textit{up-sampling} có chức năng tăng kích thước của ảnh bằng cách chèn các điểm mới giữa các điểm hiện có, được dùng phổ biến trong các mô hình tạo sinh, nhằm tăng kích thước của đầu ra so với đầu vào},
	short={up-sampling},
}

%convolution
\newglossaryentry{convolution}{
	name={convolution},
	description={Toán tử \textit{convolution}~\cite{convolution} là một toán tử được sử dụng trong mạng tích chập, dùng để trích xuất đặc trưng của tín hiệu},
	short={convolution},
}

%histogram
\newglossaryentry{histogram}{
	name={histogram},
	description={Là một biểu đồ cột biểu diễn sự phân bố các giá trị màu sắc hoặc mức xám trong một hình ảnh. Biểu đồ này cung cấp một cái nhìn tổng quan về tần suất xuất hiện của các giá trị màu sắc khác nhau trong ảnh, từ đó có thể hiểu rõ hơn về đặc điểm của ảnh, chẳng hạn như độ sáng, độ tương phản, và sự cân bằng màu.
	 },
	short={histogram},
}

%bilinear
\newglossaryentry{bilinear}{
	name={bilinear},
	description={Hay gọi đầy đủ là \textit{Bilinear interpolation}  \cite{mastylo2013bilinear}- Nội suy song tuyến tính, là phương pháp được sử dụng phổ biến để phóng to hoặc thu nhỏ ảnh. Giá trị của điểm ảnh mới được tính toán dựa trên trung bình trọng số của 4 điểm ảnh lân cận theo cả trục ngang ($x$) và dọc ($y$).},
	short={bilinear},
}


\newglossaryentry{epoch}{
	name={epoch},
	description={Một vòng lặp hoàn chỉnh qua toàn bộ tập dữ liệu huấn luyện. Trong một \textit{epoch}, mô hình được cập nhật nhiều lần, mỗi lần với một batch dữ liệu},
	short={epoch}
}

\newglossaryentry{batch}{
	name={batch},
	description={Là một tập con của dữ liệu huấn luyện được sử dụng trong một lần lan truyền tiến và lan truyền ngược trong quá trình huấn luyện. Việc chia dữ liệu thành các batch giúp tối ưu hóa bộ nhớ và tăng tốc quá trình huấn luyện thông qua tính toán song song},
	short={batch},
}

\newglossaryentry{overfitting}{
	name={overfitting},
	description={Là hiện tượng xảy ra khi mô hình học quá kỹ các chi tiết và nhiễu trong tập huấn luyện, dẫn đến hiệu suất kém khi áp dụng cho dữ liệu chưa từng thấy. Mô hình bị \textit{overfitting} sẽ có sai số huấn luyện thấp nhưng sai số kiểm tra cao},
	short={overfitting},
}

\newglossaryentry{adam}{
	name={adam},
	description={Thuật toán tối ưu phổ biến trong huấn luyện mạng nơ-ron, kết hợp giữa momentum và điều chỉnh tốc độ học theo từng tham số. Tên đầy đủ là Adaptive Moment Estimation},
	short={adam},
}

\newglossaryentry{cnn}{
	name={CNN},
	description={Mạng nơ-ron tích chập, thường được dùng trong các bài toán xử lý ảnh và nhận dạng mẫu. CNN sử dụng các lớp tích chập để tự động học các đặc trưng không gian từ dữ liệu ảnh đầu vào.},
	first={Convolutional Neural Network (CNN)},
	plural={CNNs}
}

\newglossaryentry{skipconnection}{
	name={skip connection},
	description={Kết nối bỏ qua; kỹ thuật kết nối đầu vào của một lớp với đầu ra của lớp sâu hơn, thường dùng trong mạng sâu như ResNet để giảm hiện tượng mất mát thông tin và giúp gradient lan truyền dễ dàng hơn.}
}


\newglossaryentry{fft}{
	name={FFT},
	description={viết tắt của \textit{Fast Fourier Transform}, tức Biến đổi Fourier nhanh. Đây là thuật toán hiệu quả để chuyển đổi tín hiệu từ miền thời gian sang miền tần số, thường được dùng trong xử lý tín hiệu và phân tích ảnh},
	first={biến đổi Fourier nhanh (FFT)},
	plural={FFTs}
}

\newglossaryentry{ifft}{
	name={iFFT},
	description={viết tắt của \textit{Inverse Fast Fourier Transform}, tức Biến đổi Fourier ngược nhanh. Đây là thuật toán dùng để chuyển tín hiệu từ miền tần số trở về miền thời gian},
	first={biến đổi Fourier ngược nhanh (iFFT)},
	plural={iFFTs}
}

\newglossaryentry{dft}{
	name={DFT},
	description={viết tắt của \textit{Discrete Fourier Transform}, tức Biến đổi Fourier rời rạc. Đây là phép biến đổi dùng để phân tích một tín hiệu rời rạc theo miền tần số},
	first={biến đổi Fourier rời rạc (DFT)},
	plural={DFTs}
}

\newglossaryentry{gpu}{
	name={GPU},
	description={viết tắt của \textit{Graphics Processing Unit}, tức bộ xử lý đồ họa. GPU có khả năng xử lý song song cao, thường được dùng để tăng tốc quá trình huấn luyện mạng học sâu},
	first={GPU},
	plural={GPUs}
}

\newglossaryentry{deepfake}{
	name={deepfake},
	description={là từ ghép giữa “deep learning” (học sâu) và “fake” (giả mạo). Deepfake là nội dung đa phương tiện (ảnh, video, âm thanh) được tạo ra bằng các kỹ thuật học sâu, khiến chúng trông như thật nhưng thực tế là giả mạo},
	first={deepfake},
	plural={deepfakes}
}

\newglossaryentry{bce}{
	name={binary cross-entropy},
	description={là một hàm mất mát được dùng phổ biến trong các bài toán phân lớp nhị phân, giúp đo lường sự khác biệt giữa xác suất dự đoán và nhãn thực tế},
	first={binary cross-entropy},
	plural={}
}

\newglossaryentry{knowledgedistillation}{
	name={knowledge distillation},
	description={là kỹ thuật huấn luyện mô hình nhỏ hơn (student) bằng cách học từ mô hình lớn hơn (teacher), thông qua đầu ra hoặc biểu diễn đặc trưng trung gian},
	first={knowledge distillation},
	plural={}
}

\newglossaryentry{fbkd}{
	name={feature-based knowledge distillation},
	description={là một kỹ thuật trong huấn luyện mạng học sâu, trong đó một mô hình nhỏ hơn (student) học từ mô hình lớn hơn (teacher) thông qua đặc trưng trung gian (feature), thay vì chỉ học từ đầu ra cuối cùng},
	first={rút trích tri thức dựa trên đặc trưng (Feature-Based Knowledge Distillation)},
	plural={Feature-Based Knowledge Distillation}
}

\newglossaryentry{distillation}{
	name={distillation},
	description={trong lĩnh vực học sâu, distillation (rút trích tri thức) là kỹ thuật huấn luyện một mô hình nhỏ (student) bằng cách học theo hành vi hoặc biểu diễn của một mô hình lớn đã được huấn luyện trước (teacher)},
	first={distillation},
	plural={}
}

\newglossaryentry{stride}{
	name={stride},
	description={là một tham số trong lớp tích chập (convolution) hoặc pooling, biểu thị số bước mà cửa sổ trượt di chuyển trên ảnh đầu vào. Stride càng lớn thì kích thước đầu ra càng nhỏ},
	first={stride},
	plural={}
}

\newglossaryentry{padding}{
	name={padding},
	description={là kỹ thuật thêm các giá trị (thường là 0) xung quanh biên của ảnh đầu vào trong mạng tích chập. Mục đích là để giữ nguyên kích thước không gian đầu ra hoặc kiểm soát kích thước khi thực hiện phép tích chập},
	first={padding},
	plural={}
}

\newglossaryentry{relu}{
	name={ReLU},
	description={viết tắt của \textit{Rectified Linear Unit}, là một hàm kích hoạt trong mạng nơ-ron, được định nghĩa là \( f(x) = \max(0, x) \). ReLU giúp mô hình học phi tuyến và có khả năng lan truyền gradient hiệu quả hơn},
	first={ReLU (Rectified Linear Unit)},
	plural={}
}

\newglossaryentry{kernel}{
	name={kernel},
	description={trong mạng nơ-ron tích chập, kernel (hay còn gọi là filter) là một ma trận trọng số nhỏ dùng để quét qua ảnh đầu vào và trích xuất các đặc trưng như biên, góc cạnh, họa tiết,...},
	first={kernel},
	plural={kernels}
}

\newglossaryentry{maxpooling}{
	name={max pooling},
	description={là một phép toán trong mạng nơ-ron tích chập dùng để giảm kích thước đầu ra bằng cách lấy giá trị lớn nhất trong mỗi vùng nhỏ của ảnh đặc trưng. Max Pooling giúp giảm số lượng tham số và tăng tính khái quát của mô hình},
	first={max pooling},
	plural={}
}

\newglossaryentry{gap}{
	name={global average pooling},
	description={là một kỹ thuật trong mạng nơ-ron tích chập, thay vì dùng các lớp fully connected, GAP tính trung bình toàn bộ mỗi bản đồ đặc trưng (feature map) và tạo ra một đầu ra duy nhất cho mỗi kênh. Phương pháp này giúp giảm số lượng tham số và hạn chế overfitting},
	first={global average pooling},
	plural={}
}

\newglossaryentry{fc}{
	name={fully connected layer},
	description={là lớp trong mạng nơ-ron trong đó mỗi đầu vào được kết nối với tất cả các nút ở lớp tiếp theo. Lớp này thường xuất hiện ở cuối mô hình để đưa ra quyết định phân loại},
	first={fully connected layer},
	plural={}
}

\newglossaryentry{sigmoid}{
	name={sigmoid},
	description={là một hàm kích hoạt trong mạng nơ-ron, được định nghĩa là \( \sigma(x) = \frac{1}{1 + e^{-x}} \). Hàm sigmoid đưa đầu ra về khoảng (0, 1), thích hợp cho các bài toán phân lớp nhị phân},
	first={sigmoid},
	plural={}
}

\newglossaryentry{generator}{
	name={generator},
	description={trong mô hình GAN, generator là mạng học sâu có nhiệm vụ sinh ra dữ liệu giả sao cho giống dữ liệu thật nhất có thể, nhằm đánh lừa discriminator},
	first={generator (mạng sinh dữ liệu giả)},
	plural={generators}
}

\newglossaryentry{discriminator}{
	name={discriminator},
	description={trong mô hình GAN, discriminator là mạng học sâu có nhiệm vụ phân biệt dữ liệu thật và dữ liệu do generator tạo ra},
	first={discriminator (mạng phân biệt thật – giả)},
	plural={discriminators}
}

\newglossaryentry{gaussian}{
	name={gaussian},
	description={là một phân phối xác suất liên tục có dạng hình chuông đối xứng, còn gọi là phân phối chuẩn (normal distribution), được sử dụng rộng rãi trong thống kê và học máy để mô hình hóa dữ liệu nhiễu hoặc phân bố tự nhiên},
	first={gaussian},
	plural={}
}

\newglossaryentry{grayscale}{
	name={gray-scale},
	description={là dạng ảnh chỉ bao gồm các mức độ xám, mỗi điểm ảnh được biểu diễn bằng một giá trị cường độ ánh sáng, thường từ 0 (đen) đến 255 (trắng)},
	first={gray-scale},
	plural={}
}

\newglossaryentry{texture}{
	name={texture},
	description={thuật ngữ trong xử lý ảnh biểu thị các mẫu lặp lại hoặc sự thay đổi cường độ ánh sáng, màu sắc trên bề mặt hình ảnh, dùng để mô tả độ mịn, nhám hoặc cấu trúc vật liệu},
	first=kết cấu bề mặt (texture),
	plural={textures}
}

\newglossaryentry{poortexteregion}{
	name={poor texture regions},
	description={các vùng ảnh có rất ít thông tin kết cấu, bề mặt tương đối đồng đều và ít thay đổi về cường độ, khiến việc phát hiện đặc trưng trở nên khó khăn},
	first={vùng kết cấu đơn giản (poor texture regions)},
	plural={}
}

\newglossaryentry{richtexteregion}{
	name={rich texture regions},
	description={các vùng ảnh chứa nhiều thông tin kết cấu, có sự thay đổi rõ rệt về cường độ hoặc hoa văn, giúp trích xuất đặc trưng dễ dàng hơn},
	first={vùng kết cấu phức tạp (rich texture regions)},
	plural={}
}

\newglossaryentry{patch}{
	name={patch},
	description={một vùng nhỏ hình vuông hoặc hình chữ nhật được trích xuất từ hình ảnh gốc, thường được sử dụng để phân tích cục bộ hoặc huấn luyện mô hình học sâu},
	first={mảnh ảnh nhỏ (patch)},
	plural={patches}
}

\newglossaryentry{azimuthalaveraging}{
	name={azimuthal averaging},
	description={kỹ thuật tính trung bình các giá trị theo hướng góc (azimuth) trong hệ tọa độ cực, thường được áp dụng trên ảnh hoặc phổ tần số để rút gọn dữ liệu thành một hàm một chiều theo bán kính},
	first={trung bình theo phương góc (azimuthal averaging)},
	plural={}
}

\newglossaryentry{svm}{
	name={SVM},
	description={là một thuật toán học có giám sát được sử dụng để phân loại và hồi quy, hoạt động bằng cách tìm siêu phẳng tối ưu phân tách các lớp dữ liệu khác nhau},
	first={Support Vector Machine (SVM)},
	plural={}
}

\newglossaryentry{kmeans}{
	name={K-means},
	description={là thuật toán phân cụm không có giám sát, chia dữ liệu thành $K$ nhóm sao cho khoảng cách nội nhóm được tối thiểu hoá. Thuật toán hoạt động bằng cách cập nhật các tâm cụm và gán lại nhãn lặp đi lặp lại cho đến khi hội tụ},
	first={K-means},
	plural={}
}

\newglossaryentry{logisticregression}{
	name={Logistic Regression},
	description={là một mô hình học có giám sát dùng để giải bài toán phân loại nhị phân, dựa trên hàm sigmoid để ánh xạ đầu ra về khoảng xác suất $[0, 1]$},
	first={hồi quy logistic (Logistic Regression)},
	plural={}
}

\newglossaryentry{dct}{
	name={DCT},
	description={là một phép biến đổi tương tự như biến đổi Fourier, dùng để biểu diễn tín hiệu dưới dạng tổ hợp các hàm cosine với tần số khác nhau. DCT thường được sử dụng trong nén ảnh và xử lý tín hiệu do khả năng tập trung năng lượng tốt},
	first={biến đổi Cosine rời rạc (Discrete Cosine Transform – DCT)},
	plural={}
}

\newglossaryentry{nearestneighbor}{
	name={nearest neighbor},
	description={là phương pháp nội suy đơn giản trong xử lý ảnh, trong đó mỗi điểm mới được gán giá trị của điểm lân cận gần nhất. Phương pháp này rất nhanh nhưng có thể tạo ra ảnh bậc thang và thiếu mượt mà},
	first={phương pháp láng giềng gần nhất (nearest neighbor)},
	plural={}
}


\newglossaryentry{binomial}{
	name={binomial filter},
	description={là bộ lọc làm mượt hình ảnh dựa trên hệ số nhị thức Pascal. Trong nội suy, binomial filter giúp làm trơn dữ liệu đầu ra bằng cách sử dụng các trọng số giống Gaussian một cách đơn giản},
	first={bộ lọc nhị thức (binomial filter)},
	plural={}
}

\newglossaryentry{binomialupsampling}{
	name={binomial up-sampling},
	description={là kỹ thuật phóng to ảnh bằng cách chèn thêm điểm ảnh (zero-insertion) và sau đó làm mượt bằng bộ lọc nhị thức (binomial filter). Phương pháp này giúp giảm hiện tượng răng cưa và tạo ảnh mượt mà hơn so với nội suy đơn giản},
	first={nội suy nhị thức (binomial up-sampling)},
	plural={}
}

\newglossaryentry{optimizer}{
	name={optimizer},
	description={là thuật toán tối ưu dùng trong huấn luyện mạng học sâu, nhằm cập nhật các tham số mô hình để giảm hàm mất mát. Một số thuật toán tối ưu phổ biến gồm SGD, Adam, RMSProp},
	first={optimizer},
	plural={}
}

\newglossaryentry{learningrate}{
	name={learning rate},
	description={là siêu tham số quyết định bước nhảy trong quá trình cập nhật tham số mô hình. Giá trị learning rate quá lớn có thể gây dao động, còn quá nhỏ khiến quá trình huấn luyện chậm},
	first={learning rate},
	plural={}
}

\newglossaryentry{batchsize}{
	name={batch size},
	description={là số lượng mẫu được sử dụng trong mỗi lần cập nhật tham số trong quá trình huấn luyện. Batch size ảnh hưởng đến tốc độ huấn luyện, bộ nhớ và độ ổn định của mô hình},
	first={batch size},
	plural={}
}

\newglossaryentry{pytorch}{
	name={PyTorch},
	description={là một thư viện mã nguồn mở chuyên dùng để xây dựng và huấn luyện các mô hình học sâu, hỗ trợ linh hoạt cả nghiên cứu và triển khai thực tế, phát triển bởi Facebook AI Research},
	first={PyTorch},
	plural={}
}

\newglossaryentry{batchnorm}{
	name={batch normalization},
	description={Kỹ thuật chuẩn hoá dữ liệu đầu vào của từng lớp trong mạng nơ-ron bằng cách đưa chúng về phân phối chuẩn (zero mean, unit variance) trong mỗi mini-batch, giúp tăng tốc quá trình huấn luyện và cải thiện độ ổn định của mô hình}
}

\newglossaryentry{bottleneck}{
	name=bottleneck,
	description={Một khối trong kiến trúc ResNet gồm ba lớp convolution liên tiếp (1×1, 3×3, 1×1), giúp giảm chi phí tính toán mà vẫn giữ được khả năng học đặc trưng}
}

\newglossaryentry{mse}{
	name={MSE},
	description={là viết tắt của \textit{Mean Squared Error}, một hàm mất mát phổ biến dùng để đo sai số bình phương trung bình giữa đầu ra dự đoán và nhãn thật trong các mô hình học máy},
	first={Mean Squared Error (MSE)},
	plural={}
}

\newglossaryentry{teacher}{
	name={teacher},
	description={Mô hình được huấn luyện trước, đóng vai trò truyền đạt tri thức cho mô hình Student thông qua cơ chế lan truyền tri thức (Knowledge Distillation)},
	plural={}
}

\newglossaryentry{student}{
	name={student},
	description={Mô hình nhẹ hơn, được huấn luyện bằng cách học theo đầu ra của mô hình Teacher thông qua lan truyền tri thức},
	plural={}
}

\newglossaryentry{layer}{
	name={layer},
	description={là một tầng trong mạng nơ-ron, thực hiện một phép biến đổi dữ liệu đầu vào thành đầu ra. Các loại layer phổ biến gồm convolutional layer, pooling layer và fully connected layer},
	first={layer},
	plural={layers}
}

\newglossaryentry{attention}{
	name={attention},
	description={là cơ chế giúp mô hình học sâu tập trung vào các phần thông tin quan trọng hơn trong chuỗi đầu vào, được sử dụng phổ biến trong mô hình Transformer và các biến thể của nó},
	first={attention},
	plural={}
}

\newglossaryentry{classification}{
	name={classification},
	description={là một dạng bài toán trong học máy, trong đó mô hình học cách phân loại đầu vào vào các nhóm hoặc lớp đã biết. Các loại phân loại gồm phân loại nhị phân, phân loại đa lớp, v.v.},
	first={classification},
	plural={}
}

\newglossaryentry{train}{
	name={train},
	description={giai đoạn huấn luyện mô hình, trong đó mô hình học từ tập dữ liệu huấn luyện (training data) để tối ưu hóa các tham số},
	first={train},
	plural={}
}

\newglossaryentry{validation}{
	name={validation},
	description={là quá trình đánh giá mô hình trong quá trình huấn luyện bằng tập dữ liệu riêng biệt, nhằm điều chỉnh siêu tham số và tránh overfitting},
	first={validation},
	plural={}
}

\newglossaryentry{test}{
	name={test},
	description={là giai đoạn kiểm tra hiệu suất mô hình sau khi huấn luyện, sử dụng tập dữ liệu chưa từng thấy để đánh giá khả năng tổng quát hóa},
	first={test},
	plural={}
}

\newglossaryentry{pipeline}{
	name=pipeline,
	description={chuỗi các bước xử lý dữ liệu được tổ chức theo thứ tự nhằm thực hiện một tác vụ nhất định, thường được sử dụng trong học máy, xử lý ảnh, hoặc các hệ thống kỹ thuật số tự động}
}

\newglossaryentry{gradient}{
	name=gradient,
	description={Đạo hàm bậc nhất theo không gian, biểu diễn mức độ và hướng biến thiên cục bộ của tín hiệu hoặc ảnh số}
}

\newglossaryentry{adof}{
	name={ADOF},
	description={Adjacency Difference Orientation Filter - khối tiền xử lý dựa trên bộ lọc thông cao trong miền không gian},
	first={Adjacency Difference Orientation Filter (ADOF)},
	plural={}
}


